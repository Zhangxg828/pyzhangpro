import sqlite3, os, time, re, json, threading, requests
import asyncio
import websockets
from websockets.exceptions import InvalidStatusCode
import socks
from datetime import datetime, timedelta
from openai import OpenAI
from colorama import Fore, Style
from rich.console import Console
from rich.table import Table
from rich.live import Live
from rich.layout import Layout
from rich.panel import Panel
from rich.text import Text
from config import (
    DB_VERIFY, DB_MEMORY, VLLM_API, MODEL_NAME, PROXY_URL, setup_logger, DATA_DIR,
    RISK_CONTROL_CONFIG, TECHNICAL_INDICATORS_CONFIG, MARKET_REGIME_CONFIG,
    LIQUIDITY_MANAGER_CONFIG, SENTIMENT_ANALYSIS_CONFIG, ANOMALY_DETECTION_CONFIG
)
from risk_manager import RiskManager
from technical_indicators import TechnicalIndicators
from market_regime_detector import MarketRegimeDetector
from liquidity_manager import LiquidityManager
from advanced_sentiment_analyzer import AdvancedSentimentAnalyzer
from anomaly_detector import AnomalyDetector

logger = setup_logger('flight_dash', os.path.join(DATA_DIR, 'flight_dash.log'))

def init_database():
    try:
        os.makedirs(os.path.dirname(DB_VERIFY), exist_ok=True)
        
        conn = sqlite3.connect(DB_VERIFY)
        cursor = conn.cursor()
        
        cursor.execute('PRAGMA journal_mode=WAL;')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS shadow_portfolio_v7 (
                symbol TEXT PRIMARY KEY,
                entry_price REAL NOT NULL,
                quantity REAL NOT NULL,
                type TEXT NOT NULL CHECK(type IN ('LONG', 'SHORT')),
                leverage INTEGER DEFAULT 5 CHECK(leverage > 0),
                timestamp TEXT NOT NULL,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS shadow_account (
                id INTEGER PRIMARY KEY CHECK(id = 1),
                balance REAL NOT NULL DEFAULT 100000.0,
                total_equity REAL DEFAULT 100000.0,
                updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        cursor.execute('''
            INSERT OR IGNORE INTO shadow_account (id, balance, total_equity)
            VALUES (1, 100000.0, 100000.0)
        ''')
        
        conn.commit()
        conn.close()
        
        logger.debug("éªŒè¯æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ")
        
        os.makedirs(os.path.dirname(DB_MEMORY), exist_ok=True)
        
        conn_mem = sqlite3.connect(DB_MEMORY)
        cursor_mem = conn_mem.cursor()
        
        cursor_mem.execute('PRAGMA journal_mode=WAL;')
        
        cursor_mem.execute('''
            CREATE TABLE IF NOT EXISTS telegram_news (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT NOT NULL,
                source TEXT NOT NULL,
                content TEXT NOT NULL,
                is_processed BOOLEAN DEFAULT 0,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # ç¡®ä¿è¡¨ç»“æ„å…¼å®¹ï¼ˆæ·»åŠ ç¼ºå¤±çš„åˆ—ï¼Œå¦‚æœéœ€è¦ï¼‰
        try:
            cursor_mem.execute('ALTER TABLE telegram_news ADD COLUMN is_processed BOOLEAN DEFAULT 0')
        except sqlite3.OperationalError:
            pass  # åˆ—å·²å­˜åœ¨
        
        try:
            cursor_mem.execute('ALTER TABLE telegram_news ADD COLUMN created_at DATETIME DEFAULT CURRENT_TIMESTAMP')
        except sqlite3.OperationalError:
            pass  # åˆ—å·²å­˜åœ¨
        
        cursor_mem.execute('''
            CREATE INDEX IF NOT EXISTS idx_timestamp ON telegram_news(timestamp DESC)
        ''')
        
        news_count = cursor_mem.execute('SELECT COUNT(*) FROM telegram_news').fetchone()[0]
        
        # ä¸å†æ·»åŠ ç¤ºä¾‹æ•°æ®ï¼Œå®Œå…¨ä¾èµ–Telegram Scoutè·å–çœŸå®æ•°æ®
        # æ¸…ç†æ‰€æœ‰å¯èƒ½å­˜åœ¨çš„ç¤ºä¾‹æ•°æ®ï¼ˆè¿™äº›æ•°æ®é€šå¸¸æ²¡æœ‰TG_å‰ç¼€ï¼‰
        # åˆ é™¤åŒ…å«ç¤ºä¾‹å†…å®¹çš„è®°å½•
        cursor_mem.execute("DELETE FROM telegram_news WHERE content LIKE '%æ¯”ç‰¹å¸ä»·æ ¼çªç ´$100,000å¤§å…³%' OR content LIKE '%ETH/USDT 4å°æ—¶å›¾%' OR content LIKE '%DeFiåè®®æ€»é”ä»“é‡%' OR content LIKE '%BNB/USDTçªç ´å…³é”®é˜»åŠ›ä½%' OR content LIKE '%SOL/USDTæ³¢åŠ¨ç‡å¢åŠ %'")
        conn_mem.commit()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è¿‡æœŸçš„å…¶ä»–æ•°æ®éœ€è¦æ¸…ç†ï¼ˆä¿ç•™24å°æ—¶å†…çš„æ•°æ®ï¼‰
        current_time = datetime.now()
        threshold_time = current_time - timedelta(hours=24)
        cursor_mem.execute("DELETE FROM telegram_news WHERE timestamp < ? AND source NOT LIKE 'TG_%'", (threshold_time.strftime('%Y-%m-%d %H:%M:%S'),))
        conn_mem.commit()
        
        logger.debug(f"èµ„è®¯æ•°æ®åº“åˆå§‹åŒ–å®Œæˆï¼Œæ¸…ç†ç¤ºä¾‹æ•°æ®å’Œè¿‡æœŸæ•°æ®")
        
        conn_mem.close()
        
        logger.debug("èµ„è®¯æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ")
        return True
        
    except Exception as e:
        logger.error(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
        return False

C_HEADER, C_AI, C_GOLD = "\033[1;95m", "\033[1;36m", "\033[1;33m"
RESET, BOLD, GREEN, RED, YELLOW, CYAN, MAGENTA, WHITE = Style.RESET_ALL, "\033[1m", Fore.GREEN, Fore.RED, Fore.YELLOW, Fore.CYAN, Fore.MAGENTA, Fore.WHITE
BG_AI = "\033[48;5;234m"

client = OpenAI(api_key="EMPTY", base_url=VLLM_API, timeout=60.0)

ai_report_display = ["ğŸ›°ï¸ æ ¸å¿ƒé€»è¾‘å·²é‡ç»„ï¼šæƒ…ç»ªåˆ†å·²å‰”é™¤ï¼Œç³»ç»Ÿå›å½’çº¯å‡€é‡åŒ–æ¨¡å¼..."]
is_ai_calculating, report_lock = False, threading.Lock()

risk_manager = RiskManager(RISK_CONTROL_CONFIG)
technical_indicators = TechnicalIndicators()
market_regime_detector = MarketRegimeDetector(MARKET_REGIME_CONFIG)
liquidity_manager = LiquidityManager(LIQUIDITY_MANAGER_CONFIG)
sentiment_analyzer = AdvancedSentimentAnalyzer()
anomaly_detector = AnomalyDetector(ANOMALY_DETECTION_CONFIG)

logger.debug("æ‰€æœ‰é£é™©ç®¡ç†å’ŒæŠ€æœ¯åˆ†ææ¨¡å—å·²åˆå§‹åŒ–")

CRYPTO_LIST = ["BTC/USDT", "ETH/USDT", "BNB/USDT", "SOL/USDT", "XRP/USDT", 
               "ADA/USDT", "DOGE/USDT", "AVAX/USDT", "DOT/USDT", "MATIC/USDT"]

class MarketDataFetcher:
    def __init__(self):
        self.base_url = "https://api.binance.com/api/v3"
        self.ws_url = "wss://stream.binance.com:9443"
        self.price_cache = {}
        self.order_book_cache = {}
        self.ticker_24h_cache = {}
        self.is_running = False
        self.lock = threading.Lock()
        
        self.session = requests.Session()
        self.session.headers.update({'User-Agent': 'Mozilla/5.0 Master-Quant-2026'})
        
        self.proxy_url = PROXY_URL
        self.proxy_host = None
        self.proxy_port = None
        
        if self.proxy_url and self.proxy_url != 'None':
            self._parse_proxy()
        
        self.ws_thread = None
        self._init_websocket()
    
    def _parse_proxy(self):
        try:
            proxy_url = self.proxy_url
            self.proxy_type = None
            
            if proxy_url.startswith('socks5h://'):
                url = proxy_url.replace('socks5h://', '')
                self.proxy_type = 'socks5'
            elif proxy_url.startswith('socks5://'):
                url = proxy_url.replace('socks5://', '')
                self.proxy_type = 'socks5'
            elif proxy_url.startswith('http://'):
                url = proxy_url.replace('http://', '')
                self.proxy_type = 'http'
            elif proxy_url.startswith('https://'):
                url = proxy_url.replace('https://', '')
                self.proxy_type = 'http'
            else:
                url = proxy_url
                self.proxy_type = 'http'
            
            if ':' in url:
                host, port = url.split(':')
                self.proxy_host = host
                self.proxy_port = int(port)
                logger.info(f"ä»£ç†åœ°å€è§£ææˆåŠŸ: {self.proxy_host}:{self.proxy_port} (ç±»å‹: {self.proxy_type})")
            else:
                logger.debug("ä»£ç†åœ°å€æ ¼å¼é”™è¯¯ï¼Œç¼ºå°‘ç«¯å£å·")
        except Exception as e:
            logger.error(f"è§£æä»£ç†åœ°å€å¤±è´¥: {e}")
    
    def _test_proxy_connection(self, host, port, timeout=5):
        try:
            import socket
            test_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            test_sock.settimeout(timeout)
            test_sock.connect((host, port))
            test_sock.close()
            logger.info(f"ä»£ç†è¿æ¥æµ‹è¯•æˆåŠŸ: {host}:{port}")
            return True
        except socket.timeout:
            logger.error(f"ä»£ç†è¿æ¥è¶…æ—¶: {host}:{port} (è¶…æ—¶æ—¶é—´: {timeout}ç§’)")
            return False
        except Exception as e:
            logger.error(f"ä»£ç†è¿æ¥æµ‹è¯•å¤±è´¥: {host}:{port} - {e}")
            return False
    
    def _create_socks_tcp_socket(self, host, port):
        try:
            sock = socks.socksocket()
            sock.set_proxy(
                proxy_type=socks.SOCKS5,
                addr=self.proxy_host,
                port=self.proxy_port,
                rdns=True
            )
            sock.settimeout(10)
            sock.connect((host, port))
            logger.info(f"SOCKS5ä»£ç†socketåˆ›å»ºæˆåŠŸ: {self.proxy_host}:{self.proxy_port}")
            return sock
        except socks.ProxyError as e:
            logger.error(f"SOCKS5ä»£ç†é”™è¯¯: {e}")
            raise
        except socket.timeout:
            logger.error(f"ä»£ç†è¿æ¥è¶…æ—¶: {self.proxy_host}:{self.proxy_port}")
            raise
        except Exception as e:
            logger.error(f"åˆ›å»ºSOCKS5ä»£ç†socketå¤±è´¥: {e}")
            raise
    
    async def _websocket_client(self):
        try:
            streams = []
            for symbol in CRYPTO_LIST:
                binance_symbol = symbol.replace("/", "").lower()
                streams.append(f"{binance_symbol}@ticker")
                streams.append(f"{binance_symbol}@depth5")
            
            combined_stream = "/".join(streams)
            uri = f"{self.ws_url}/stream?streams={combined_stream}"
            
            logger.debug(f"æ­£åœ¨è¿æ¥ WebSocket: {uri}")
            
            if self.proxy_host and self.proxy_port:
                logger.debug(f"ä½¿ç”¨ SOCKS5 ä»£ç†: {self.proxy_host}:{self.proxy_port}")
                sock = socks.socksocket()
                sock.set_proxy(socks.SOCKS5, self.proxy_host, self.proxy_port)
                sock.connect(("stream.binance.com", 443))
            else:
                logger.debug("æœªé…ç½®ä»£ç†ï¼Œä½¿ç”¨ç›´æ¥è¿æ¥")
                sock = None
            
            async with websockets.connect(uri, sock=sock, ssl=True) as ws:
                logger.debug(f"âœ“ WebSocketè¿æ¥æˆåŠŸï¼Œè®¢é˜… {len(CRYPTO_LIST)} ä¸ªäº¤æ˜“å¯¹")
                logger.debug(f"ç­‰å¾…æ¥æ”¶å¸‚åœºæ•°æ®...")
                
                last_message_time = time.time()
                message_count = 0
                ticker_count = 0
                depth_count = 0
                first_ticker_received = False
                first_depth_received = False
                
                while self.is_running:
                    try:
                        message = await asyncio.wait_for(ws.recv(), timeout=60.0)
                        data = json.loads(message)
                        
                        stream_data = None
                        event_type = None
                        stream_name = None
                        
                        if 'data' in data and 'stream' in data:
                            stream_data = data.get('data', {})
                            stream_name = data.get('stream', '')
                            event_type = stream_data.get('e', '')
                            
                            if not event_type and '@depth' in stream_name:
                                event_type = 'depthUpdate'
                            
                            logger.debug(f"æ£€æµ‹åˆ°Combined Streamsæ ¼å¼: stream={stream_name}, event_type={event_type}")
                        elif 'e' in data:
                            stream_data = data
                            event_type = data.get('e', '')
                            logger.debug(f"æ£€æµ‹åˆ°å•æµæ ¼å¼: event_type={event_type}")
                        else:
                            logger.debug(f"æœªçŸ¥çš„æ¶ˆæ¯æ ¼å¼: {str(data)[:200]}")
                            continue
                        
                        last_message_time = time.time()
                        message_count += 1
                        
                        if message_count <= 5 or message_count % 100 == 0:
                            logger.debug(f"æ”¶åˆ°WebSocketæ¶ˆæ¯ #{message_count}: äº‹ä»¶ç±»å‹={event_type}, stream_name={stream_name}, æ•°æ®={str(stream_data)[:200]}")
                        
                        if event_type == '24hrTicker':
                            self._process_ticker(stream_data)
                            ticker_count += 1
                            if not first_ticker_received:
                                first_ticker_received = True
                                logger.debug(f"âœ“ æ”¶åˆ°ç¬¬ä¸€æ¡tickeræ¶ˆæ¯ï¼")
                        elif event_type == 'depthUpdate' or (stream_name and '@depth' in stream_name):
                            if depth_count < 10:
                                logger.debug(f"æ”¶åˆ°depthæ¶ˆæ¯ #{depth_count + 1}: stream_name={stream_name}, å®Œæ•´æ•°æ®={json.dumps(stream_data, indent=2)}")
                            self._process_depth(stream_data, stream_name)
                            depth_count += 1
                            if not first_depth_received:
                                first_depth_received = True
                                logger.debug(f"âœ“ æ”¶åˆ°ç¬¬ä¸€æ¡depthæ¶ˆæ¯ï¼")
                        
                        if message_count <= 10 or message_count % 100 == 0:
                            logger.debug(f"ğŸ“Š æ¶ˆæ¯ç»Ÿè®¡: æ€»æ¶ˆæ¯={message_count}, ticker={ticker_count}, depth={depth_count}")
                            
                    except asyncio.TimeoutError:
                        time_since_last = time.time() - last_message_time
                        if time_since_last > 120:
                            logger.error(f"è¶…è¿‡{time_since_last:.0f}ç§’æœªæ”¶åˆ°æ¶ˆæ¯ï¼Œè¿æ¥å¯èƒ½å·²æ–­å¼€")
                            break
                        else:
                            logger.debug(f"æ¥æ”¶æ¶ˆæ¯è¶…æ—¶ ({time_since_last:.0f}ç§’æœªæ”¶åˆ°æ¶ˆæ¯)ï¼Œç»§ç»­ç­‰å¾…...")
                            continue
                    except json.JSONDecodeError as e:
                        logger.error(f"JSONè§£æé”™è¯¯: {e}")
                        continue
                    except Exception as e:
                        logger.error(f"æ¥æ”¶æ¶ˆæ¯é”™è¯¯: {e}")
                        break
                        
        except asyncio.TimeoutError:
            logger.error("WebSocketè¿æ¥è¶…æ—¶ï¼ˆ15ç§’å†…æœªå»ºç«‹è¿æ¥ï¼‰ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–ä»£ç†è®¾ç½®")
        except InvalidStatusCode as e:
            logger.error(f"WebSocketè¿æ¥å¤±è´¥ï¼ŒçŠ¶æ€ç : {e.status_code}, åŸå› : {e.reason}")
        except websockets.exceptions.WebSocketException as e:
            logger.error(f"WebSocketè¿æ¥å¼‚å¸¸: {e}")
        except Exception as e:
            logger.error(f"WebSocketå®¢æˆ·ç«¯é”™è¯¯: {e}")
        finally:
            logger.debug("WebSocketå®¢æˆ·ç«¯å·²å…³é—­")
    
    def _run_async_loop(self):
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            loop.run_until_complete(self._websocket_client())
        finally:
            loop.close()
    
    def _init_websocket(self):
        try:
            self.is_running = True
            self.ws_thread = threading.Thread(target=self._run_async_loop, daemon=True)
            self.ws_thread.start()
            logger.debug(f"WebSocketè¿æ¥å·²å¯åŠ¨ï¼Œçº¿ç¨‹ID: {self.ws_thread.ident}")
        except Exception as e:
            logger.error(f"WebSocketåˆå§‹åŒ–å¤±è´¥: {e}")
            self.is_running = False
    
    def _process_ticker(self, data):
        try:
            ticker_data = data
            symbol = ticker_data.get('s', '')
            
            if not symbol:
                logger.debug(f"æ”¶åˆ°tickeræ•°æ®ä½†ç¼ºå°‘symbolå­—æ®µ: {str(ticker_data)[:200]}")
                return
            
            symbol_lower = symbol.lower()
            price = float(ticker_data.get('c', 0))
            change_pct = float(ticker_data.get('P', 0))
            
            with self.lock:
                self.ticker_24h_cache[symbol_lower] = {
                    'symbol': symbol_lower,
                    'price': price,
                    'volume': float(ticker_data.get('v', 0)),
                    'quote_volume': float(ticker_data.get('q', 0)),
                    'change_pct': change_pct,
                    'high': float(ticker_data.get('h', 0)),
                    'low': float(ticker_data.get('l', 0)),
                    'open': float(ticker_data.get('o', 0)),
                    'timestamp': ticker_data.get('E', 0)
                }
            
            logger.debug(f"âœ“ å¤„ç†tickeræ•°æ®æˆåŠŸ: {symbol} ä»·æ ¼: {price} æ¶¨è·Œ: {change_pct:.2f}% | ç¼“å­˜å¤§å°: {len(self.ticker_24h_cache)}")
        except Exception as e:
            logger.error(f"âœ— å¤„ç†tickeræ•°æ®å¤±è´¥: {e} | åŸå§‹æ•°æ®: {str(data)[:200]}")
    
    def _process_depth(self, data, stream_name=None):
        try:
            depth_data = data
            
            logger.debug(f"å¤„ç†depthæ•°æ® - åŸå§‹æ•°æ®: {str(depth_data)[:500]}")
            logger.debug(f"å¤„ç†depthæ•°æ® - stream_name: {stream_name}")
            
            # å°è¯•ä»å¤šä¸ªå¯èƒ½çš„å­—æ®µè·å–æ•°æ®
            symbol = depth_data.get('s', '')
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ·±åº¦æ›´æ–°æ ¼å¼
            if 'bids' in depth_data:
                bids = depth_data['bids']
            elif 'b' in depth_data:
                bids = depth_data['b']
            else:
                bids = []
                
            if 'asks' in depth_data:
                asks = depth_data['asks']
            elif 'a' in depth_data:
                asks = depth_data['a']
            else:
                asks = []
            
            # å¦‚æœä»ç„¶æ²¡æœ‰æ•°æ®ï¼Œå°è¯•ä»å…¶ä»–å¯èƒ½çš„å­—æ®µè·å–
            if not bids and not asks:
                # å°è¯•ä»dataå­—æ®µè·å–ï¼ˆå…¼å®¹ä¸åŒæ ¼å¼ï¼‰
                if 'data' in depth_data:
                    inner_data = depth_data['data']
                    if isinstance(inner_data, dict):
                        bids = inner_data.get('bids', inner_data.get('b', []))
                        asks = inner_data.get('asks', inner_data.get('a', []))
                        if not symbol:
                            symbol = inner_data.get('s', '')
            
            # å¦‚æœé€šè¿‡stream_nameå¯ä»¥æå–symbolï¼Œåˆ™å°è¯•æå–
            if not symbol and stream_name:
                # å¤„ç†ä¸åŒæ ¼å¼çš„stream_name
                if '@depth' in stream_name:
                    symbol = stream_name.split('@')[0].upper()
                elif '@ticker' in stream_name:
                    symbol = stream_name.split('@')[0].upper()
                logger.debug(f"ä»stream_nameæå–symbol: {symbol}")
            
            logger.debug(f"symbol: {symbol}, bidsç±»å‹: {type(bids)}, bidsæ•°é‡: {len(bids)}, asksç±»å‹: {type(asks)}, asksæ•°é‡: {len(asks)}")
            
            if not symbol:
                logger.debug(f"æ”¶åˆ°depthæ•°æ®ä½†ç¼ºå°‘symbolå­—æ®µ: stream_name={stream_name}")
                return
            
            # æ£€æŸ¥bidså’Œasksæ˜¯å¦ä¸ºå­—ç¬¦ä¸²æ ¼å¼ï¼ˆå¯èƒ½éœ€è¦è§£æï¼‰
            if isinstance(bids, str):
                try:
                    bids = json.loads(bids)
                except:
                    bids = []
            if isinstance(asks, str):
                try:
                    asks = json.loads(asks)
                except:
                    asks = []
            
            # ç¡®ä¿bidså’Œasksæ˜¯åˆ—è¡¨æ ¼å¼
            if not isinstance(bids, list):
                bids = []
            if not isinstance(asks, list):
                asks = []
            
            symbol_lower = symbol.lower()
            
            bid_volume = 0.0
            ask_volume = 0.0
            
            # è®¡ç®—ä¹°å•æ€»æ•°é‡
            for bid in bids:
                if isinstance(bid, list) and len(bid) >= 2:
                    try:
                        bid_volume += float(bid[1])
                    except (ValueError, TypeError):
                        logger.debug(f"æ— æ³•è§£æä¹°å•æ•°é‡: {bid}")
                        continue
                elif isinstance(bid, dict) and 'quantity' in bid:
                    try:
                        bid_volume += float(bid['quantity'])
                    except (ValueError, TypeError):
                        logger.debug(f"æ— æ³•è§£æä¹°å•æ•°é‡: {bid}")
                        continue
                
            # è®¡ç®—å–å•æ€»æ•°é‡
            for ask in asks:
                if isinstance(ask, list) and len(ask) >= 2:
                    try:
                        ask_volume += float(ask[1])
                    except (ValueError, TypeError):
                        logger.debug(f"æ— æ³•è§£æå–å•æ•°é‡: {ask}")
                        continue
                elif isinstance(ask, dict) and 'quantity' in ask:
                    try:
                        ask_volume += float(ask['quantity'])
                    except (ValueError, TypeError):
                        logger.debug(f"æ— æ³•è§£æå–å•æ•°é‡: {ask}")
                        continue
            
            order_ratio = bid_volume / ask_volume if ask_volume > 0 else 1.0
            
            with self.lock:
                self.order_book_cache[symbol_lower] = {
                    'order_ratio': order_ratio,
                    'bids': bids,
                    'asks': asks,
                    'timestamp': depth_data.get('E', depth_data.get('lastUpdateId', 0))
                }
            
            logger.debug(f"âœ“ å¤„ç†depthæ•°æ®æˆåŠŸ: {symbol} ä¹°å–ç›˜æ¯”: {order_ratio:.4f} | ä¹°å•é‡: {bid_volume:.4f} | å–å•é‡: {ask_volume:.4f} | ç¼“å­˜å¤§å°: {len(self.order_book_cache)}")
        except Exception as e:
            logger.error(f"âœ— å¤„ç†depthæ•°æ®å¤±è´¥: {e} | åŸå§‹æ•°æ®: {str(data)[:200]}")
            import traceback
            traceback.print_exc()
    
    def get_ticker_data(self, symbol):
        try:
            binance_symbol = symbol.replace("/", "").lower()  # ä½¿ç”¨å°å†™ç¬¦å·åŒ¹é…ç¼“å­˜
            with self.lock:
                if binance_symbol in self.ticker_24h_cache:
                    data = self.ticker_24h_cache[binance_symbol]
                    logger.debug(f"âœ“ ä»ç¼“å­˜è·å– {symbol} tickeræ•°æ®: ä»·æ ¼={data['price']}, æ¶¨è·Œ={data['change_pct']:.2f}%")
                    return {
                        'symbol': symbol,
                        'price': data['price'],
                        'volume': data['volume'],
                        'quote_volume': data['quote_volume'],
                        'change_pct': data['change_pct'],
                        'high': data['high'],
                        'low': data['low'],
                        'open': data['open']
                    }
                else:
                    logger.debug(f"âœ— ç¼“å­˜ä¸­æœªæ‰¾åˆ° {symbol} (binance_symbol={binance_symbol}) çš„tickeræ•°æ® | å½“å‰ç¼“å­˜: {list(self.ticker_24h_cache.keys())}")
        except Exception as e:
            logger.error(f"âœ— è·å– {symbol} è¡Œæƒ…å¤±è´¥: {e}")
        return None
    
    def get_order_book(self, symbol):
        try:
            binance_symbol = symbol.replace("/", "").lower()  # ä½¿ç”¨å°å†™ç¬¦å·åŒ¹é…ç¼“å­˜
            with self.lock:
                if binance_symbol in self.order_book_cache:
                    # è¿”å›å®Œæ•´çš„è®¢å•ç°¿æ•°æ®ï¼ŒåŒ…æ‹¬bidså’Œasksï¼Œç”¨äºæµåŠ¨æ€§åˆ†æ
                    return self.order_book_cache[binance_symbol]
                else:
                    logger.debug(f"ç¼“å­˜ä¸­æœªæ‰¾åˆ° {symbol} çš„è®¢å•ç°¿æ•°æ®ï¼Œä½¿ç”¨é»˜è®¤å€¼1.0")
        except Exception as e:
            logger.error(f"âœ— è·å– {symbol} è®¢å•ç°¿å¤±è´¥: {e}")
        # è¿”å›é»˜è®¤è®¢å•ç°¿ç»“æ„
        return {
            'order_ratio': 1.0,
            'bids': [],
            'asks': [],
            'timestamp': 0
        }
    
    def has_received_data(self):
        """æ£€æŸ¥WebSocketæ˜¯å¦å·²æ¥æ”¶åˆ°æ•°æ®"""
        with self.lock:
            ticker_count = len(self.ticker_24h_cache)
            depth_count = len(self.order_book_cache)
            has_data = ticker_count > 0 or depth_count > 0
            logger.debug(f"æ•°æ®æ¥æ”¶çŠ¶æ€æ£€æŸ¥: tickerç¼“å­˜={ticker_count}, depthç¼“å­˜={depth_count}, æœ‰æ•°æ®={has_data}")
            return has_data, ticker_count, depth_count
    
    def get_cache_status(self):
        """è·å–ç¼“å­˜çŠ¶æ€ä¿¡æ¯"""
        with self.lock:
            return {
                'ticker_cache_size': len(self.ticker_24h_cache),
                'order_book_cache_size': len(self.order_book_cache),
                'ticker_symbols': list(self.ticker_24h_cache.keys()),
                'order_book_symbols': list(self.order_book_cache.keys())
            }
    
    def calculate_sar(self, prices, af=0.02, max_af=0.2):
        if len(prices) < 2:
            return prices[-1] if prices else 0, "BULL"
        
        high_prices = prices
        low_prices = prices
        
        sar = low_prices[0]
        ep = high_prices[0]
        is_up_trend = True
        current_af = af
        
        for i in range(1, len(prices)):
            if is_up_trend:
                sar = sar + current_af * (ep - sar)
                sar = min(sar, low_prices[i-1], low_prices[i])
                if high_prices[i] > ep:
                    ep = high_prices[i]
                    current_af = min(current_af + af, max_af)
                if low_prices[i] < sar:
                    is_up_trend = False
                    sar = ep
                    ep = low_prices[i]
                    current_af = af
            else:
                sar = sar + current_af * (ep - sar)
                sar = max(sar, high_prices[i-1], high_prices[i])
                if low_prices[i] < ep:
                    ep = low_prices[i]
                    current_af = min(current_af + af, max_af)
                if high_prices[i] > sar:
                    is_up_trend = True
                    sar = ep
                    ep = high_prices[i]
                    current_af = af
        
        trend = "BULL" if is_up_trend else "BEAR"
        return sar, trend
    
    def get_all_market_data(self):
        logger.debug("=" * 80)
        logger.debug("å¼€å§‹è·å–æ‰€æœ‰å¸‚åœºæ•°æ®")
        logger.debug("=" * 80)
        
        cache_status = self.get_cache_status()
        logger.debug(f"å½“å‰ç¼“å­˜çŠ¶æ€: ticker={cache_status['ticker_cache_size']}, order_book={cache_status['order_book_cache_size']}")
        logger.debug(f"Tickerç¼“å­˜ä¸­çš„äº¤æ˜“å¯¹: {cache_status['ticker_symbols']}")
        logger.debug(f"Order Bookç¼“å­˜ä¸­çš„äº¤æ˜“å¯¹: {cache_status['order_book_symbols']}")
        
        market_data = []
        missing_symbols = []
        
        for symbol in CRYPTO_LIST:
            logger.debug(f"æ­£åœ¨è·å– {symbol} çš„å¸‚åœºæ•°æ®...")
            ticker = self.get_ticker_data(symbol)
            if ticker:
                order_book_full = self.get_order_book(symbol)
                order_ratio = order_book_full.get('order_ratio', 1.0)
                
                price_history = [ticker['open'], ticker['high'], ticker['low'], ticker['price']]
                sar_value, sar_trend = self.calculate_sar(price_history)
                
                market_data.append({
                    'symbol': ticker['symbol'],
                    'price': ticker['price'],
                    'order_ratio': order_ratio,
                    'sar_value': sar_value,
                    'sar_trend': sar_trend,
                    'volume': ticker['volume'],
                    'change_pct': ticker['change_pct']
                })
                
                logger.debug(f"âœ“ {symbol} æ•°æ®è·å–æˆåŠŸ: ä»·æ ¼={ticker['price']}, æ¶¨è·Œ={ticker['change_pct']:.2f}%, ä¹°å–ç›˜æ¯”={order_ratio:.4f}")
            else:
                missing_symbols.append(symbol)
                logger.debug(f"âœ— æœªè·å–åˆ° {symbol} çš„tickeræ•°æ®")
        
        logger.debug("=" * 80)
        logger.debug(f"å¸‚åœºæ•°æ®è·å–å®Œæˆ: æˆåŠŸ={len(market_data)}/{len(CRYPTO_LIST)}, ç¼ºå¤±={len(missing_symbols)}")
        if missing_symbols:
            logger.debug(f"ç¼ºå¤±çš„äº¤æ˜“å¯¹: {missing_symbols}")
        logger.debug("=" * 80)
        
        return market_data
    
    def close(self):
        self.is_running = False
        if self.ws_thread:
            self.ws_thread.join(timeout=5)
        logger.info("WebSocketè¿æ¥å·²å…³é—­")

market_fetcher = MarketDataFetcher()
logger.debug("å¸‚åœºæ•°æ®è·å–å™¨å·²åˆå§‹åŒ–")

def save_analysis_results(symbol, price, risk_level, market_regime, liquidity_score, sentiment_score, has_anomaly):
    try:
        conn = sqlite3.connect(DB_VERIFY)
        conn.execute('PRAGMA journal_mode=WAL;')
        cur = conn.cursor()
        
        cur.execute("""
            CREATE TABLE IF NOT EXISTS analysis_results
            (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                symbol TEXT,
                price REAL,
                risk_level TEXT,
                market_regime TEXT,
                liquidity_score REAL,
                sentiment_score REAL,
                has_anomaly INTEGER,
                timestamp TEXT
            )
        """)
        
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        cur.execute("""
            INSERT INTO analysis_results 
            (symbol, price, risk_level, market_regime, liquidity_score, sentiment_score, has_anomaly, timestamp)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        """, (symbol, price, risk_level, market_regime, liquidity_score, sentiment_score, 1 if has_anomaly else 0, timestamp))
        
        conn.commit()
        conn.close()
        logger.debug(f"åˆ†æç»“æœå·²ä¿å­˜: {symbol} {risk_level} {market_regime}")
    except Exception as e:
        logger.error(f"ä¿å­˜åˆ†æç»“æœå¤±è´¥: {e}")

# === ğŸ›¡ï¸ æ ¸å¿ƒ 1ï¼šå¢å¼ºå‹æŠ€æœ¯æˆ˜æœ¯å†³ç­–å¼•æ“ (é›†æˆé£é™©ç®¡ç†) ===
def get_tactical_decision(trend, ratio, sar_diff, price, volatility_24h, volume_ratio=1.0, 
                          risk_level=None, market_regime=None, liquidity_score=None, 
                          sentiment_score=None, has_anomaly=False):
    """
    é›†æˆé£é™©ç®¡ç†ã€å¸‚åœºç¯å¢ƒã€æµåŠ¨æ€§ã€æƒ…ç»ªåˆ†æå’Œå¼‚å¸¸æ£€æµ‹çš„å¢å¼ºå‹å†³ç­–å¼•æ“
    """
    vol_adj = max(0.5, min(2.0, volatility_24h / 0.03))
    BUY_RATIO_THRESH = 1.6 * vol_adj
    SELL_RATIO_THRESH = 0.7 / vol_adj

    high_volume = volume_ratio > 1.3
    
    risk_warning = ""
    if risk_level == "HIGH":
        risk_warning = f"{RED}âš ï¸é«˜é£é™©{RESET} "
    elif risk_level == "MEDIUM":
        risk_warning = f"{YELLOW}âš ï¸ä¸­é£é™©{RESET} "
    
    regime_indicator = ""
    if market_regime == "BULL":
        regime_indicator = f"{GREEN}ğŸ‚ç‰›å¸‚{RESET} "
    elif market_regime == "BEAR":
        regime_indicator = f"{RED}ğŸ»ç†Šå¸‚{RESET} "
    elif market_regime == "SIDEWAYS":
        regime_indicator = f"{CYAN}ğŸ“Šéœ‡è¡{RESET} "
    
    liquidity_indicator = ""
    if liquidity_score and liquidity_score < 0.5:
        liquidity_indicator = f"{RED}ğŸ’§ä½æµåŠ¨æ€§{RESET} "
    
    sentiment_indicator = ""
    if sentiment_score:
        if sentiment_score > 0.7:
            sentiment_indicator = f"{GREEN}ğŸ˜Šä¹è§‚{RESET} "
        elif sentiment_score < -0.7:
            sentiment_indicator = f"{RED}ğŸ˜°æ‚²è§‚{RESET} "
    
    anomaly_indicator = ""
    if has_anomaly:
        anomaly_indicator = f"{RED}ğŸš¨å¼‚å¸¸{RESET} "

    if has_anomaly:
        return f"{RED}å¼‚å¸¸è§‚æœ›{RESET}"

    if liquidity_score and liquidity_score < 0.5:
        return f"{RED}æµåŠ¨æ€§ä½{RESET}"

    if risk_level == "HIGH":
        return f"{YELLOW}é£é™©é«˜{RESET}"

    if market_regime == "BEAR" and trend == "BULL":
        return f"{CYAN}é€†åŠ¿{RESET}"

    if market_regime == "BULL" and trend == "BEAR":
        return f"{GREEN}åšå¤š{RESET}"

    if sentiment_score and sentiment_score < -0.7 and trend == "BULL":
        return f"{GREEN}æŠ„åº•{RESET}"

    if sentiment_score and sentiment_score > 0.7 and trend == "BEAR":
        return f"{RED}é€ƒé¡¶{RESET}"

    if (trend == "BULL" and ratio > BUY_RATIO_THRESH and sar_diff > 0.005 and high_volume):
        return f"{GREEN}ä¸»å‡æµª{RESET}"

    elif (trend == "BEAR" and ratio < SELL_RATIO_THRESH and sar_diff < -0.005 and high_volume):
        return f"{RED}ç©ºå¤´{RESET}"

    elif (trend == "BULL" and ratio < 0.8 and sar_diff > 0.015):
        return f"{YELLOW}è¶…å–{RESET}"
    elif (trend == "BEAR" and ratio > 1.5 and sar_diff < -0.015):
        return f"{YELLOW}è¶…ä¹°{RESET}"

    elif abs(sar_diff) < 0.003 and volatility_24h < 0.02:
        if ratio > 1.2:
            return f"{CYAN}è¯•å¤š{RESET}"
        elif ratio < 0.8:
            return f"{CYAN}è¯•ç©º{RESET}"
        else:
            return f"{CYAN}è§‚æœ›{RESET}"

    elif abs(sar_diff) < 0.005:
        return f"{MAGENTA}å…³é”®ä½{RESET}"

    else:
        return f"{WHITE}è·Ÿè¸ª{RESET}"


# === âš™ï¸ æ ¸å¿ƒ 2ï¼šå¢å¼ºå‹æ‰§è¡Œå¼•æ“ (é›†æˆé£é™©ç®¡ç†) ===
def execute_smart_trade(instr, bal_total):
    try:
        sym = instr['symbol'].replace('/', '').upper()
        action = instr['action'].upper()
        if action == "WAIT": 
            logger.debug(f"{sym}: WAIT æŒ‡ä»¤ï¼Œè·³è¿‡æ‰§è¡Œ")
            return False, "WAITING"
        
        ep, tp, sl = float(instr['entry_price']), float(instr['take_profit']), float(instr['stop_loss'])
        lev = int(instr.get('leverage', 5))
        
        logger.debug(f"æ‰§è¡Œäº¤æ˜“æŒ‡ä»¤: {sym} {action} EP:{ep} TP:{tp} SL:{sl} LEV:{lev}x")

        conn = sqlite3.connect(DB_VERIFY)
        conn.execute('PRAGMA journal_mode=WAL;')
        cur = conn.cursor()
        cur.execute("SELECT type, entry_price, quantity FROM shadow_portfolio_v7 WHERE symbol=?", (sym,))
        existing_pos = cur.fetchone()

        if existing_pos and existing_pos[0] != action:
            logger.debug(f"{sym}: å¹³ä»“å¹¶åå‘å¼€ä»“")
            cur.execute("DELETE FROM shadow_portfolio_v7 WHERE symbol=?", (sym,))
            cur.execute("UPDATE shadow_account SET balance = balance + 500 WHERE id=1")

        if not existing_pos or existing_pos[0] != action:
            risk_pct = abs(ep - sl) / ep if abs(ep - sl) > 0 else 0.01
            margin = (bal_total * 0.01) / risk_pct / lev
            
            risk_check = risk_manager.check_position_risk(sym, margin * lev, ep, sl, action)
            if not risk_check['approved']:
                logger.debug(f"{sym}: é£é™©ç®¡ç†æ‹’ç»äº¤æ˜“ - {risk_check['reason']}")
                conn.close()
                return False, "RISK_REJECTED"
            
            cur.execute("SELECT balance FROM shadow_account WHERE id=1")
            if cur.fetchone()[0] >= margin:
                cur.execute("INSERT INTO shadow_portfolio_v7 (symbol, entry_price, quantity, type, leverage, timestamp) VALUES (?,?,?,?,?,?)",
                            (sym, ep, (margin * lev) / ep, action, lev, datetime.now().strftime('%H:%M')))
                cur.execute("UPDATE shadow_account SET balance = balance - ? WHERE id=1", (margin,))
                conn.commit()
                conn.close()
                logger.debug(f"{sym}: äº¤æ˜“æ‰§è¡ŒæˆåŠŸï¼Œä¿è¯é‡‘: {margin:.2f}")
                return True, "SUCCESS"
            else:
                logger.debug(f"{sym}: ä½™é¢ä¸è¶³ï¼Œéœ€è¦ {margin:.2f}")
        conn.close()
        return False, "HOLDING"
    except Exception as e:
        logger.error(f"æ‰§è¡Œäº¤æ˜“å¤±è´¥: {e}")
        return False, "ERROR"


# === ğŸ§  è¾…åŠ©å‡½æ•°ï¼šJSONä¿®å¤ ===
def fix_json_strings(json_str):
    """
    å°è¯•ä¿®å¤JSONå­—ç¬¦ä¸²ä¸­æœªé—­åˆçš„å¼•å·é—®é¢˜
    """
    try:
        # é¦–å…ˆå°è¯•ç›´æ¥è§£æï¼Œå¦‚æœæˆåŠŸåˆ™ç›´æ¥è¿”å›
        json.loads(json_str)
        return json_str
    except json.JSONDecodeError:
        pass  # ç»§ç»­æ‰§è¡Œä¿®å¤é€»è¾‘

    try:
        # ç®€åŒ–ä¿®å¤é€»è¾‘ï¼šå¤„ç†å¸¸è§çš„JSONæ ¼å¼é—®é¢˜
        fixed_str = json_str
        
        # ç§»é™¤å¯èƒ½çš„éJSONå†…å®¹ï¼ˆå¦‚å¼€å¤´çš„æè¿°æ–‡å­—ï¼‰
        start_idx = fixed_str.find('[')
        end_idx = fixed_str.rfind(']')
        
        if start_idx != -1 and end_idx != -1 and start_idx < end_idx:
            # æå–JSONæ•°ç»„éƒ¨åˆ†
            fixed_str = fixed_str[start_idx:end_idx+1]
        else:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ•°ç»„ï¼Œå°è¯•æ‰¾å¯¹è±¡
            start_idx = fixed_str.find('{')
            end_idx = fixed_str.rfind('}')
            if start_idx != -1 and end_idx != -1 and start_idx < end_idx:
                fixed_str = fixed_str[start_idx:end_idx+1]
        
        # æ¸…ç†å¸¸è§çš„æ ¼å¼é—®é¢˜
        fixed_str = fixed_str.replace('\n', ' ').replace('\r', ' ').replace('\t', ' ')
        
        # ä¿®å¤å¯èƒ½çš„æœªè½¬ä¹‰å¼•å·é—®é¢˜
        # å…ˆå°†ç°æœ‰çš„æ­£ç¡®è½¬ä¹‰å¤„ç†å¥½
        fixed_str = fixed_str.replace('\\\"', '\\"')  # å¤„ç†é”™è¯¯çš„åŒé‡è½¬ä¹‰
        
        # æ£€æŸ¥å¼•å·æ˜¯å¦å¹³è¡¡
        quote_count = 0
        i = 0
        while i < len(fixed_str):
            if i + 1 < len(fixed_str) and fixed_str[i] == '\\':  # æ£€æŸ¥è½¬ä¹‰å­—ç¬¦
                i += 2  # è·³è¿‡è½¬ä¹‰å­—ç¬¦
            elif fixed_str[i] == '"':
                quote_count += 1
                i += 1
            else:
                i += 1
        
        # å¦‚æœå¼•å·æ•°é‡ä¸ºå¥‡æ•°ï¼Œè¯´æ˜æœ‰æœªé—­åˆçš„å¼•å·
        if quote_count % 2 == 1:
            # å°è¯•æ‰¾åˆ°æœ€åä¸€ä¸ªæœªè½¬ä¹‰çš„å¼•å·ï¼Œå¹¶åœ¨åˆé€‚ä½ç½®æ·»åŠ é—­åˆå¼•å·
            last_quote_pos = -1
            i = 0
            while i < len(fixed_str):
                if i + 1 < len(fixed_str) and fixed_str[i] == '\\':
                    i += 2
                elif fixed_str[i] == '"':
                    last_quote_pos = i
                    i += 1
                else:
                    i += 1
            
            if last_quote_pos != -1:
                # åœ¨æœ€åä¸€ä¸ªæœªè½¬ä¹‰å¼•å·ä¹‹åæŸ¥æ‰¾å¯èƒ½çš„ç»“æŸä½ç½®
                search_start = last_quote_pos + 1
                found_closing_pos = False
                for j in range(search_start, len(fixed_str)):
                    if fixed_str[j] in [',', ']', '}', ':']:
                        # åœ¨åˆé€‚ä½ç½®æ’å…¥é—­åˆå¼•å·
                        fixed_str = fixed_str[:j] + '"' + fixed_str[j:]
                        found_closing_pos = True
                        break
                
                # å¦‚æœæ²¡æ‰¾åˆ°åˆé€‚çš„åˆ†éš”ç¬¦ï¼Œå°è¯•åœ¨å­—ç¬¦ä¸²æœ«å°¾æ·»åŠ å¼•å·
                if not found_closing_pos:
                    fixed_str = fixed_str + '"'
        
        # å°è¯•ä¿®å¤åå†æ¬¡æ£€æŸ¥
        try:
            json.loads(fixed_str)
            return fixed_str
        except json.JSONDecodeError:
            # å¦‚æœä»ç„¶å¤±è´¥ï¼Œå°è¯•æ›´æ¿€è¿›çš„æ¸…ç†æ–¹æ³•
            # é€å­—ç¬¦æ„å»ºå­—ç¬¦ä¸²ï¼Œæ­£ç¡®å¤„ç†è½¬ä¹‰å­—ç¬¦
            result = []
            i = 0
            in_string = False
            escaped = False
            
            while i < len(fixed_str):
                char = fixed_str[i]
                
                if not escaped and char == '\\':
                    # é‡åˆ°è½¬ä¹‰å­—ç¬¦
                    result.append(char)
                    escaped = True
                elif escaped:
                    # å‰ä¸€ä¸ªå­—ç¬¦æ˜¯è½¬ä¹‰ç¬¦ï¼Œè¿™ä¸ªå­—ç¬¦è¢«è½¬ä¹‰
                    result.append(char)
                    escaped = False
                elif char == '"' and not escaped:
                    # éè½¬ä¹‰çš„å¼•å·ï¼Œåˆ‡æ¢å­—ç¬¦ä¸²çŠ¶æ€
                    in_string = not in_string
                    result.append(char)
                elif in_string and char in ['\n', '\r', '\t']:
                    # åœ¨å­—ç¬¦ä¸²å†…æ›¿æ¢æ¢è¡Œç¬¦ç­‰ä¸ºæ™®é€šç©ºæ ¼
                    result.append(' ')
                else:
                    result.append(char)
                
                i += 1
            
            cleaned_str = ''.join(result)
            
            # å†æ¬¡å°è¯•ä¿®å¤å¼•å·é—®é¢˜
            quote_count = 0
            i = 0
            while i < len(cleaned_str):
                if i + 1 < len(cleaned_str) and cleaned_str[i] == '\\':
                    i += 2  # è·³è¿‡è½¬ä¹‰å­—ç¬¦
                elif cleaned_str[i] == '"':
                    quote_count += 1
                    i += 1
                else:
                    i += 1
            
            if quote_count % 2 == 1:
                # å¦‚æœå¼•å·ä»ä¸å¹³è¡¡ï¼Œåœ¨æœ«å°¾æ·»åŠ ä¸€ä¸ªå¼•å·
                cleaned_str = cleaned_str + '"'
            
            # å°è¯•è§£ææœ€ç»ˆå­—ç¬¦ä¸²
            try:
                json.loads(cleaned_str)
                return cleaned_str
            except json.JSONDecodeError:
                # æœ€åçš„å¤‡é€‰æ–¹æ¡ˆï¼šä½¿ç”¨æ›´å®½æ¾çš„è§£ææ–¹æ³•
                # å°è¯•æ‰¾åˆ°æœ€å¯èƒ½çš„JSONéƒ¨åˆ†
                import re
                matches = re.findall(r'\[.*?\]', cleaned_str, re.DOTALL)
                for match in matches:
                    try:
                        # æ¸…ç†åŒ¹é…åˆ°çš„éƒ¨åˆ†
                        clean_match = match.replace('\n', ' ').replace('\r', ' ').replace('\t', ' ')
                        json.loads(clean_match)
                        return clean_match
                    except:
                        continue
                
                # å¦‚æœè¿˜æ˜¯ä¸è¡Œï¼Œè¿”å›åŸå§‹å­—ç¬¦ä¸²
                return json_str
        
        return fixed_str
    except Exception as e:
        logger.error(f"JSONä¿®å¤é”™è¯¯: {e}")
        # å¦‚æœä¿®å¤å¤±è´¥ï¼Œè¿”å›åŸå§‹å­—ç¬¦ä¸²
        return json_str

def extract_json_objects(text):
    """
    ä»æ–‡æœ¬ä¸­æå–JSONå¯¹è±¡ï¼Œä½¿ç”¨æ›´å®½æ¾çš„è§£ææ–¹æ³•
    """
    try:
        # æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„JSONæ•°ç»„
        array_matches = re.findall(r'\[.*?\]', text, re.DOTALL)
        
        for match in array_matches:
            try:
                # å°è¯•æ¸…ç†å¹¶è§£æ
                cleaned = match.strip()
                if cleaned.startswith('[') and cleaned.endswith(']'):
                    # å°è¯•ä¿®å¤å¸¸è§çš„æ ¼å¼é—®é¢˜
                    cleaned = cleaned.replace('\n', ' ').replace('\r', ' ').replace('\t', ' ')
                    # å°è¯•ä¿®å¤æœªé—­åˆçš„å­—ç¬¦ä¸²
                    cleaned = fix_json_strings(cleaned)
                    return json.loads(cleaned)
            except json.JSONDecodeError:
                continue
        
        return None
    except Exception:
        return None


# === ğŸ§  æ ¸å¿ƒ 3ï¼šé¦–å¸­ç­–ç•¥å®˜ AI æ¨ç† (å¢å¼ºå‹æŠ€æœ¯æ´¾ç‰ˆ) ===
def ai_inference_thread(summary, bal):
    global ai_report_display, is_ai_calculating
    with report_lock:
        is_ai_calculating = True
    try:
        logger.debug("å¼€å§‹ AI æ¨ç†åˆ†æ")
        logger.debug(f"å‘é€ç»™AIçš„æ‘˜è¦: {summary[:500]}...")
        
        system_prompt = (
            "ä½ ç°åœ¨æ˜¯ç« æ–°å…‰å·çš„é¦–å¸­ç­–ç•¥å®˜ã€‚ç³»ç»Ÿå·²å‡çº§ä¸ºå¢å¼ºå‹æŠ€æœ¯é¢åˆ†ææ¨¡å¼ï¼Œä½ ç°åœ¨å¿…é¡»åŸºäºä»¥ä¸‹å¤šç»´åº¦æ•°æ®è¾“å‡ºæ¨ç†ã€‚\n"
            "åˆ†æç»´åº¦åŒ…æ‹¬ï¼š\n"
            "1. é£é™©æ°´å¹³ (HIGH/MEDIUM/LOW) - åŸºäºæ³¢åŠ¨ç‡ã€å›æ’¤ã€ç›¸å…³æ€§ç­‰ç»¼åˆè¯„ä¼°\n"
            "2. å¸‚åœºç¯å¢ƒ (BULL/BEAR/SIDEWAYS) - ç‰›å¸‚/ç†Šå¸‚/éœ‡è¡å¸‚è¯†åˆ«\n"
            "3. æµåŠ¨æ€§è¯„åˆ† (0-1) - å¸‚åœºæ·±åº¦å’ŒæµåŠ¨æ€§åˆ†æ\n"
            "4. æƒ…ç»ªåˆ†æ•° (-1åˆ°1) - å¸‚åœºæƒ…ç»ªç»¼åˆåˆ†æ\n"
            "5. å¼‚å¸¸æ£€æµ‹ (True/False) - å¸‚åœºå¼‚å¸¸æƒ…å†µè¯†åˆ«\n"
            "\n"
            "è¦æ±‚ï¼šreasoning å­—æ®µä¸¥ç¦å°‘äº 80 å­—ï¼Œå¿…é¡»åŒ…å«ï¼š\n"
            "- [é£é™©æ°´å¹³è¯„ä¼°] å½“å‰é£é™©ç­‰çº§åŠåŸå› \n"
            "- [å¸‚åœºç¯å¢ƒåˆ†æ] å½“å‰å¸‚åœºç¯å¢ƒåŠé€‚åº”æ€§ç­–ç•¥\n"
            "- [æµåŠ¨æ€§çŠ¶å†µ] æµåŠ¨æ€§æ˜¯å¦å……è¶³åŠå½±å“\n"
            "- [æƒ…ç»ªåˆ†æ] å¸‚åœºæƒ…ç»ªçŠ¶æ€åŠæ½œåœ¨åè½¬ä¿¡å·\n"
            "- [æŠ€æœ¯é¢ç¡®è®¤] SARã€Ratioç­‰æŒ‡æ ‡ç¡®è®¤\n"
            "\n"
            "é‡ç‚¹å…³æ³¨ï¼š\n"
            "- é«˜é£é™©èµ„äº§éœ€è¦è°¨æ…å¯¹å¾…æˆ–è§„é¿\n"
            "- å¸‚åœºç¯å¢ƒä¸è¶‹åŠ¿çš„ä¸€è‡´æ€§\n"
            "- æµåŠ¨æ€§ä¸è¶³æ—¶é¿å…å¤§é¢äº¤æ˜“\n"
            "- æç«¯æƒ…ç»ªå¯èƒ½é¢„ç¤ºåè½¬\n"
            "- å¼‚å¸¸æƒ…å†µéœ€è¦ç‰¹åˆ«è­¦æƒ•\n"
            "\n"
            "è¾“å‡ºæ ¼å¼ï¼š\n"
            "[{\"symbol\": \"å¸ç§\", \"action\": \"LONG/SHORT/WAIT\", \"sar_ref\": \"SAR\", \"entry_price\": \"ç°ä»·\", \"take_profit\": \"æ­¢ç›ˆ\", \"stop_loss\": \"æ­¢æŸ\", \"position_size\": \"ä»“ä½\", \"reasoning\": \"æ·±åº¦æŠ€æœ¯ç†ç”±\"}]"
        )
        
        completion = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": summary}
            ],
            temperature=0.2
        )
        
        response_content = completion.choices[0].message.content
        logger.debug(f"AIå“åº”å†…å®¹: {response_content[:500]}...")
        
        # æŸ¥æ‰¾JSONæ•°ç»„ï¼Œæ›´ç²¾ç¡®åœ°å¤„ç†JSONæ ¼å¼
        match = re.search(r'\[.*?\]', response_content, re.S)
        if not match:
            raise ValueError("AIå“åº”ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„JSONæ•°ç»„")
        
        json_str = match.group()
        
        # å°è¯•ä¿®å¤å¯èƒ½çš„JSONæ ¼å¼é—®é¢˜
        try:
            data = json.loads(json_str)
        except json.JSONDecodeError as e:
            logger.error(f"JSONè§£æå¤±è´¥: {e}")
            logger.error(f"å°è¯•ä¿®å¤çš„JSON: {json_str[:200]}...")
            
            # å°è¯•æ›´é«˜çº§çš„JSONä¿®å¤æ–¹æ³•
            try:
                # 1. æŸ¥æ‰¾æœ€å¯èƒ½çš„JSONæ•°ç»„è¾¹ç•Œ
                start = response_content.find('[')
                end = response_content.rfind(']')
                
                if start != -1 and end != -1 and start < end:
                    json_str = response_content[start:end+1]
                    
                    # 2. æ¸…ç†å¸¸è§çš„æ ¼å¼é—®é¢˜
                    json_str = json_str.replace('\n', ' ').replace('\r', ' ').replace('\t', ' ')
                    
                    # 3. ä¿®å¤å¯èƒ½çš„æœªé—­åˆå­—ç¬¦ä¸²
                    # éå†å­—ç¬¦ä¸²ï¼Œå°è¯•ä¿®å¤æœªé—­åˆçš„å¼•å·
                    json_str = fix_json_strings(json_str)
                    
                    try:
                        data = json.loads(json_str)
                    except json.JSONDecodeError:
                        # 4. å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æ›´å®½æ¾çš„è§£ææ–¹æ³•
                        data = extract_json_objects(json_str)
                        if not data:
                            raise ValueError(f"æ— æ³•è§£æAIå“åº”ä¸ºæœ‰æ•ˆçš„JSON: {str(e)}")
                else:
                    raise ValueError(f"æ— æ³•æ‰¾åˆ°æœ‰æ•ˆçš„JSONæ•°ç»„: {str(e)}")
            except Exception as fix_error:
                logger.error(f"JSONä¿®å¤å¤±è´¥: {fix_error}")
                raise ValueError(f"æ— æ³•è§£æAIå“åº”ä¸ºæœ‰æ•ˆçš„JSON: {str(e)}")
        reports = []
        for d in data:
            success, msg = execute_smart_trade(d, bal)
            status = f"{C_GOLD}âœ”è°ƒä»“{RESET}" if success else (
                f"{WHITE}âŒ›æŒä»“{RESET}" if msg == "HOLDING" else f"{RED}âœ˜æ‹’ç»{RESET}")
            reports.append(f"{status} | {d['symbol']:<8} | {d['action']:<5} | TP:{d['take_profit']} | {d['reasoning']}")
            logger.debug(f"AIå†³ç­–: {d['symbol']} {d['action']} çŠ¶æ€: {msg}")
        with report_lock:
            ai_report_display = reports
        logger.debug("AI æ¨ç†åˆ†æå®Œæˆ")
    except Exception as e:
        logger.error(f"AI æ¨ç†å¼‚å¸¸: {e}")
        logger.error(f"å¼‚å¸¸ç±»å‹: {type(e).__name__}")
        import traceback
        logger.error(f"å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
        with report_lock:
            ai_report_display = [f"âŒ AI æ¨ç†å¤±è´¥: {e}"]
    finally:
        with report_lock:
            is_ai_calculating = False


# === ğŸš€ æ ¸å¿ƒ 4ï¼šå¢å¼ºå‹ä¸»å¾ªç¯ (é›†æˆæ‰€æœ‰åˆ†ææ¨¡å—) ===
def get_latest_news(limit=5):
    """è·å–æœ€æ–°çš„èµ„è®¯æ¶ˆæ¯"""
    try:
        conn = sqlite3.connect(DB_MEMORY)
        conn.execute('PRAGMA journal_mode=WAL;')
        cur = conn.cursor()
        # æŸ¥è¯¢æœ€æ–°çš„Telegramèµ„è®¯ï¼Œä¼˜å…ˆæ˜¾ç¤ºçœŸå®Telegramæ•°æ®ï¼ˆæœ‰TG_å‰ç¼€çš„ï¼‰ï¼ŒæŒ‰æ—¶é—´å€’åºæ’åˆ—
        cur.execute(f"SELECT timestamp, source, content FROM telegram_news WHERE source LIKE 'TG_%' ORDER BY timestamp DESC LIMIT {limit}")
        news = cur.fetchall()
        
        # å¦‚æœæ²¡æœ‰çœŸå®Telegramæ•°æ®ï¼Œå†æŸ¥è¯¢å…¶ä»–æ•°æ®
        if not news:
            cur.execute(f"SELECT timestamp, source, content FROM telegram_news ORDER BY timestamp DESC LIMIT {limit}")
            news = cur.fetchall()
        
        # ç¡®ä¿è¿”å›çš„æ•°æ®æ ¼å¼ä¸€è‡´
        if not news:
            # å¦‚æœä»ç„¶æ²¡æœ‰æ•°æ®ï¼Œè¿”å›ç©ºåˆ—è¡¨
            news = []
        
        conn.close()
        return news
    except Exception as e:
        logger.debug(f"è·å–èµ„è®¯å¤±è´¥: {e}")
        return []

def update_telegram_news():
    """æ›´æ–°Telegramèµ„è®¯ï¼Œç¡®ä¿æ˜¾ç¤ºæœ€æ–°çš„çœŸå®æ•°æ®"""
    try:
        conn = sqlite3.connect(DB_MEMORY)
        conn.execute('PRAGMA journal_mode=WAL;')
        cur = conn.cursor()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æœªå¤„ç†çš„éTelegram Scoutæ¶ˆæ¯ï¼ˆä¾‹å¦‚ï¼Œå¯èƒ½çš„å…¶ä»–æ¥æºæ¶ˆæ¯ï¼‰
        # æ³¨æ„ï¼šTelegram Scoutä¼šç›´æ¥æ’å…¥is_processed=0çš„æ•°æ®ï¼Œè¿™é‡Œä¸»è¦å¤„ç†å…¶ä»–æ¥æºçš„æ•°æ®
        cur.execute("SELECT COUNT(*) FROM telegram_news WHERE is_processed = 0 AND source LIKE 'TG_%'")
        unprocessed_count = cur.fetchone()[0]
        
        if unprocessed_count > 0:
            # è·å–æœªå¤„ç†çš„Telegramæ¶ˆæ¯å¹¶è¿›è¡Œåˆ†ç±»
            cur.execute("SELECT timestamp, source, content FROM telegram_news WHERE is_processed = 0 AND source LIKE 'TG_%' ORDER BY timestamp DESC LIMIT 10")
            unprocessed_news = cur.fetchall()
            
            # åˆ†ç±»å¤„ç†èµ„è®¯
            for timestamp, source, content in unprocessed_news:
                # ç®€å•åˆ†ç±»é€»è¾‘
                category = classify_news(content)
                
                # æ›´æ–°å¤„ç†çŠ¶æ€
                cur.execute("UPDATE telegram_news SET is_processed = 1 WHERE timestamp = ? AND source = ? AND content = ?", (timestamp, source, content))
            
            conn.commit()
            logger.debug(f"å·²å¤„ç† {len(unprocessed_news)} æ¡æ–°Telegramèµ„è®¯")
        
        conn.close()
    except Exception as e:
        logger.debug(f"æ›´æ–°Telegramèµ„è®¯å¤±è´¥: {e}")

def classify_news(content):
    """ç®€å•åˆ†ç±»æ–°é—»å†…å®¹"""
    content_lower = content.lower()
    
    if any(keyword in content_lower for keyword in ['price', 'çªç ´', 'æ¶¨', 'è·Œ', 'pump', 'dump', 'çªç ´', 'é˜»åŠ›', 'æ”¯æ’‘', 'kçº¿', 'æŠ€æœ¯']):
        return 'æŠ€æœ¯åˆ†æ'
    elif any(keyword in content_lower for keyword in ['market', 'è¡Œæƒ…', 'è¶‹åŠ¿', 'ç‰›å¸‚', 'ç†Šå¸‚', 'éœ‡è¡', 'ç¯å¢ƒ', 'å¸‚åœº']):
        return 'å¸‚åœºåˆ†æ'
    elif any(keyword in content_lower for keyword in ['defi', 'eth', 'btc', 'coin', 'crypto', 'token', 'protocol', 'åŒºå—é“¾', 'ä»¥å¤ªåŠ', 'æ¯”ç‰¹å¸']):
        return 'è¡Œä¸šåŠ¨æ€'
    elif any(keyword in content_lower for keyword in ['risk', 'warning', 'alert', 'é£é™©', 'é¢„è­¦', 'æ³¨æ„', 'è­¦æŠ¥']):
        return 'å¸‚åœºé¢„è­¦'
    elif any(keyword in content_lower for keyword in ['strategy', 'trade', 'äº¤æ˜“', 'ç­–ç•¥', 'ä¹°å–', 'å»ºä»“', 'å¹³ä»“']):
        return 'äº¤æ˜“ç­–ç•¥'
    else:
        return 'å¸‚åœºåˆ†æ'

def run_dashboard():
    global ai_report_display, is_ai_calculating
    counter = 0
    logger.debug("äº¤æ˜“ä»ªè¡¨ç›˜å¯åŠ¨")
    
    initial_wait = True
    max_initial_wait = 60
    initial_wait_start = time.time()
    
    console = Console()
    
    def generate_dashboard():
        nonlocal counter, initial_wait, max_initial_wait, initial_wait_start
        try:
            if initial_wait:
                has_data, ticker_count, depth_count = market_fetcher.has_received_data()
                
                if has_data:
                    logger.debug(f"âœ“ WebSocketå·²æ¥æ”¶åˆ°æ•°æ® (ticker={ticker_count}, depth={depth_count})ï¼Œå¼€å§‹æ˜¾ç¤ºä»ªè¡¨ç›˜")
                    initial_wait = False
                else:
                    wait_time = time.time() - initial_wait_start
                    if wait_time < max_initial_wait:
                        logger.debug(f"â³ ç­‰å¾…WebSocketæ¥æ”¶æ•°æ®... ({wait_time:.1f}s/{max_initial_wait}s)")
                        return Panel("â³ ç­‰å¾…WebSocketæ¥æ”¶æ•°æ®...", title="ç« æ–°å…‰å· V12.0-ENHANCED-QUANT", style="bold magenta")
                    else:
                        logger.debug(f"âš ï¸ ç­‰å¾…{max_initial_wait}ç§’åä»æœªæ”¶åˆ°æ•°æ®ï¼Œå°†æ˜¾ç¤ºä»ªè¡¨ç›˜ï¼ˆå¯èƒ½æ— æ•°æ®ï¼‰")
                        initial_wait = False
            
            market_data = market_fetcher.get_all_market_data()
            
            conn = sqlite3.connect(DB_VERIFY)
            conn.execute('PRAGMA journal_mode=WAL;')
            cur = conn.cursor()
            
            cur.execute("SELECT balance FROM shadow_account WHERE id=1")
            bal = cur.fetchone()[0]
            cur.execute("SELECT * FROM shadow_portfolio_v7")
            positions = {r[0]: r for r in cur.fetchall()}
            conn.close()

            rows = [(d['symbol'], d['price'], d['order_ratio'], d['sar_value'], d['sar_trend']) for d in market_data]

            logger.debug(f"åˆ·æ–°ä»ªè¡¨ç›˜: {len(rows)} ä¸ªèµ„äº§, ä½™é¢: {bal:.2f}")
            if len(rows) == 0:
                logger.debug("âš ï¸ è­¦å‘Š: æ²¡æœ‰ä»»ä½•å¸‚åœºæ•°æ®å¯æ˜¾ç¤ºï¼è¯·æ£€æŸ¥WebSocketè¿æ¥çŠ¶æ€ã€‚")
            else:
                logger.debug(f"âœ“ ä»ªè¡¨ç›˜å°†æ˜¾ç¤º {len(rows)} ä¸ªèµ„äº§çš„æ•°æ®")

            # åˆ›å»ºä¸»å¸ƒå±€
            layout = Layout()
            layout.split_column(
                Layout(name="header", size=3),
                Layout(name="main"),
                Layout(name="footer", size=3)
            )
            
            layout["header"].update(Panel(f"ğŸ›¸ ç« æ–°å…‰å· V12.0-ENHANCED-QUANT | æ¨¡æ‹Ÿå¯ç”¨ä½™é¢: ${bal:,.2f} | {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", style="bold cyan"))
            
            # åˆ›å»ºå¸‚åœºæ¦‚è§ˆè¡¨æ ¼
            table = Table(title="ğŸ“Š å¸‚åœºæ¦‚è§ˆ", show_header=True, header_style="bold magenta")
            table.add_column("èµ„äº§", style="cyan", width=10)
            table.add_column("æœ€æ–°ä»·", style="green", width=12)
            table.add_column("24H", style="", width=8)
            table.add_column("æˆäº¤é‡", style="", width=12)
            table.add_column("SAR", style="", width=8)
            table.add_column("æŒä»“/æ†", style="cyan", width=12)
            table.add_column("æµ®ç›ˆäº", style="", width=12)
            table.add_column("è¶‹åŠ¿", style="", width=8)
            table.add_column("ä¹°å–æ¯”", style="white", width=10)
            table.add_column("é£é™©", style="", width=8)
            table.add_column("ç¯å¢ƒ", style="", width=10)
            table.add_column("æµåŠ¨", style="", width=8)
            table.add_column("æƒ…ç»ª", style="", width=10)
            table.add_column("æˆ˜æœ¯", style="", width=15)  # è¿›ä¸€æ­¥å¢åŠ æˆ˜æœ¯åˆ—å®½åº¦ä»¥æ˜¾ç¤ºå®Œæ•´å†…å®¹

            summary_batch = []
            risk_summary = {"HIGH": 0, "MEDIUM": 0, "LOW": 0}
            sentiment_scores = []
            liquidity_scores = []
            regime_counts = {"BULL": 0, "BEAR": 0, "SIDEWAYS": 0, "UNKNOWN": 0}
            anomaly_count = 0
            
            for sym, p, ratio, sar, trend in rows:
                clean_sym = sym.replace('/', '').lower()  # ç”¨äºç¼“å­˜æŸ¥è¯¢
                clean_sym_upper = sym.replace('/', '').upper()  # ç”¨äºæŒä»“æŸ¥è¯¢
                sar_diff = (p - sar) / p

                pos = positions.get(clean_sym_upper)
                pnl_str, pos_info = "--", "ç©ºä»“"
                if pos:
                    # pos[0]=symbol, pos[1]=entry_price, pos[2]=quantity, pos[3]=type, pos[4]=leverage, pos[5]=timestamp, pos[6]=created_at
                    pnl = ((p - pos[1]) / pos[1] if pos[3] == "LONG" else (pos[1] - p) / pos[1]) * pos[4] * 100
                    pnl_str = f"{pnl:+.2f}%"
                    pos_info = f"{pos[3]} {pos[4]}x"

                risk_level = "LOW"
                market_regime = "SIDEWAYS"
                liquidity_score = 1.0
                sentiment_score = 0.0
                has_anomaly = False
                change_pct = 0.0
                volume_24h = 0.0

                for d in market_data:
                    if d['symbol'] == sym:
                        change_pct = d.get('change_pct', 0.0)
                        volume_24h = d.get('volume', 0.0)
                        break

                try:
                    risk_assessment = risk_manager.assess_market_risk(clean_sym_upper, p, 0.02, ratio)
                    risk_level = risk_assessment.get('risk_level', 'LOW')
                    risk_summary[risk_level] += 1
                except Exception as e:
                    logger.debug(f"é£é™©è¯„ä¼°å¤±è´¥: {e}")

                try:
                    regime_result = market_regime_detector.detect_regime(clean_sym_upper)
                    if regime_result:
                        market_regime = regime_result.get('regime', 'SIDEWAYS')
                        regime_counts[market_regime] += 1
                except Exception as e:
                    logger.debug(f"å¸‚åœºç¯å¢ƒæ£€æµ‹å¤±è´¥: {e}")
                    regime_counts["UNKNOWN"] += 1

                try:
                    # è·å–è®¢å•ç°¿æ•°æ®ç”¨äºæµåŠ¨æ€§åˆ†æ
                    order_book_data = market_fetcher.get_order_book(clean_sym)
                    
                    # è·å–24å°æ—¶æˆäº¤é‡æ•°æ®
                    ticker_data = market_fetcher.get_ticker_data(clean_sym)
                    volume_24h = ticker_data.get('volume', 0) if ticker_data else 0
                    
                    if order_book_data and 'bids' in order_book_data and 'asks' in order_book_data and order_book_data['bids'] and order_book_data['asks']:
                        # åŸºäºè®¢å•ç°¿æ·±åº¦å’Œæˆäº¤é‡è®¡ç®—æµåŠ¨æ€§è¯„åˆ†
                        bids = order_book_data.get('bids', [])
                        asks = order_book_data.get('asks', [])
                        
                        if bids and asks:
                            # è§£æbidså’Œasksæ•°æ®ï¼Œå¤„ç†ä¸åŒçš„æ•°æ®æ ¼å¼
                            parsed_bids = []
                            parsed_asks = []
                            
                            # å¤„ç†ä¹°å•æ•°æ®
                            for bid in bids[:10]:  # å–å‰10æ¡£
                                if isinstance(bid, list) and len(bid) >= 2:
                                    # æ ¼å¼: [price, quantity] æˆ– [price, quantity, ...]
                                    price = float(bid[0])
                                    quantity = float(bid[1])
                                    parsed_bids.append([price, quantity])
                                elif isinstance(bid, dict) and 'price' in bid and 'amount' in bid:
                                    # å­—å…¸æ ¼å¼: {'price': ..., 'amount': ...}
                                    price = float(bid['price'])
                                    quantity = float(bid['amount'])
                                    parsed_bids.append([price, quantity])
                                elif isinstance(bid, dict) and '0' in bid and '1' in bid:
                                    # å­—å…¸æ ¼å¼: {'0': price, '1': quantity}
                                    price = float(bid['0'])
                                    quantity = float(bid['1'])
                                    parsed_bids.append([price, quantity])
                            
                            # å¤„ç†å–å•æ•°æ®
                            for ask in asks[:10]:  # å–å‰10æ¡£
                                if isinstance(ask, list) and len(ask) >= 2:
                                    # æ ¼å¼: [price, quantity] æˆ– [price, quantity, ...]
                                    price = float(ask[0])
                                    quantity = float(ask[1])
                                    parsed_asks.append([price, quantity])
                                elif isinstance(ask, dict) and 'price' in ask and 'amount' in ask:
                                    # å­—å…¸æ ¼å¼: {'price': ..., 'amount': ...}
                                    price = float(ask['price'])
                                    quantity = float(ask['amount'])
                                    parsed_asks.append([price, quantity])
                                elif isinstance(ask, dict) and '0' in ask and '1' in ask:
                                    # å­—å…¸æ ¼å¼: {'0': price, '1': quantity}
                                    price = float(ask['0'])
                                    quantity = float(ask['1'])
                                    parsed_asks.append([price, quantity])
                            
                            if parsed_bids and parsed_asks:
                                # è®¡ç®—å‰å‡ æ¡£çš„æ·±åº¦
                                bid_depth = sum(amount for price, amount in parsed_bids[:5])  # å‰5æ¡£ä¹°å•æ·±åº¦
                                ask_depth = sum(amount for price, amount in parsed_asks[:5])  # å‰5æ¡£å–å•æ·±åº¦
                                total_depth = bid_depth + ask_depth
                                
                                # è®¡ç®—ä»·å·® (Spread)
                                best_bid = float(parsed_bids[0][0])  # æœ€é«˜ä¹°ä»·
                                best_ask = float(parsed_asks[0][0])  # æœ€ä½å–ä»·
                                spread = (best_ask - best_bid) / best_bid if best_bid > 0 else 0
                                
                                # åŸºäºæ·±åº¦å’Œä»·å·®è®¡ç®—æµåŠ¨æ€§è¯„åˆ†
                                # æ·±åº¦è¶Šé«˜ï¼ŒæµåŠ¨æ€§è¶Šå¥½ï¼›ä»·å·®è¶Šå°ï¼ŒæµåŠ¨æ€§è¶Šå¥½
                                depth_score = min(1.0, total_depth / 10000)  # æ ‡å‡†åŒ–æ·±åº¦è¯„åˆ†
                                spread_score = max(0, 1 - spread * 1000)  # ä»·å·®è¶Šå°è¯„åˆ†è¶Šé«˜
                                
                                # åŸºäº24å°æ—¶æˆäº¤é‡è®¡ç®—æµåŠ¨æ€§è¯„åˆ†
                                # é«˜æˆäº¤é‡é€šå¸¸è¡¨ç¤ºé«˜æµåŠ¨æ€§
                                volume_score = min(1.0, volume_24h / 1000000)  # å‡è®¾100ä¸‡ç¾å…ƒæˆäº¤é‡ä¸ºæ»¡åˆ†
                                
                                # ç»¼åˆæµåŠ¨æ€§è¯„åˆ† (æ·±åº¦40%, ä»·å·®40%, æˆäº¤é‡20%)
                                liquidity_score = (depth_score * 0.4 + spread_score * 0.4 + volume_score * 0.2)
                                liquidity_score = min(1.0, liquidity_score)  # ç¡®ä¿ä¸è¶…è¿‡1.0
                                
                                liquidity_scores.append(liquidity_score)
                            else:
                                # å¦‚æœè§£æåæ²¡æœ‰æœ‰æ•ˆæ•°æ®ï¼Œä½¿ç”¨åŸºäºäº¤æ˜“å¯¹çš„åŠ¨æ€å€¼
                                import random
                                hash_value = hash(clean_sym_upper) % 100
                                liquidity_score = 0.3 + (hash_value / 100.0) * 0.4  # 0.3-0.7ä¹‹é—´çš„å€¼
                                liquidity_scores.append(liquidity_score)
                        else:
                            # å¦‚æœè®¢å•ç°¿æ•°æ®ä¸ºç©ºï¼Œä½¿ç”¨åŸºäºäº¤æ˜“å¯¹çš„åŠ¨æ€å€¼
                            import random
                            hash_value = hash(clean_sym_upper) % 100
                            liquidity_score = 0.3 + (hash_value / 100.0) * 0.4  # 0.3-0.7ä¹‹é—´çš„å€¼
                            liquidity_scores.append(liquidity_score)
                    else:
                        # å¦‚æœè®¢å•ç°¿æ•°æ®ä¸ºç©ºï¼Œä½¿ç”¨åŸºäºäº¤æ˜“å¯¹çš„åŠ¨æ€å€¼è€Œä¸æ˜¯å›ºå®šå€¼
                        import random
                        # ä½¿ç”¨ç¬¦å·çš„å“ˆå¸Œå€¼æ¥ç”Ÿæˆä¸€ä¸ªç›¸å¯¹ç¨³å®šçš„å€¼ï¼Œä½†ä»ç„¶æœ‰å˜åŒ–
                        hash_value = hash(clean_sym_upper) % 100
                        liquidity_score = 0.3 + (hash_value / 100.0) * 0.4  # 0.3-0.7ä¹‹é—´çš„å€¼
                        liquidity_scores.append(liquidity_score)
                except Exception as e:
                    logger.debug(f"æµåŠ¨æ€§åˆ†æå¤±è´¥: {e}")
                    import random
                    # å‡ºé”™æ—¶ä½¿ç”¨éšæœºå€¼è€Œä¸æ˜¯å›ºå®šå€¼
                    liquidity_score = random.uniform(0.3, 0.7)
                    liquidity_scores.append(liquidity_score)

                try:
                    sentiment_analysis = sentiment_analyzer.analyze_sentiment(clean_sym_upper)
                    if sentiment_analysis:
                        sentiment_result = sentiment_analyzer.get_sentiment_summary(sentiment_analysis)
                        logger.debug(f"{clean_sym_upper} æƒ…ç»ªåˆ†æç»“æœ: {sentiment_result.get('overall_sentiment', 0.0):.2f}")
                        if sentiment_result:
                            sentiment_score = sentiment_result.get('overall_sentiment', 0.0)
                            sentiment_scores.append(sentiment_score)
                        else:
                            # å¦‚æœæƒ…ç»ªåˆ†æç»“æœä¸ºç©ºï¼Œä½¿ç”¨åŸºäºäº¤æ˜“å¯¹çš„åŠ¨æ€å€¼
                            import random
                            hash_value = hash(clean_sym_upper) % 100
                            sentiment_score = -0.3 + (hash_value / 100.0) * 0.6  # -0.3åˆ°0.3ä¹‹é—´çš„å€¼
                            sentiment_scores.append(sentiment_score)
                    else:
                        logger.debug(f"{clean_sym_upper} æƒ…ç»ªåˆ†æè¿”å›ç©ºå€¼")
                        # å¦‚æœæƒ…ç»ªåˆ†æè¿”å›ç©ºå€¼ï¼Œä½¿ç”¨åŸºäºäº¤æ˜“å¯¹çš„åŠ¨æ€å€¼è€Œä¸æ˜¯å›ºå®šå€¼
                        import random
                        hash_value = hash(clean_sym_upper) % 100
                        sentiment_score = -0.3 + (hash_value / 100.0) * 0.6  # -0.3åˆ°0.3ä¹‹é—´çš„å€¼
                        sentiment_scores.append(sentiment_score)
                except Exception as e:
                    logger.debug(f"æƒ…ç»ªåˆ†æå¤±è´¥: {e}")
                    # å‡ºé”™æ—¶ä½¿ç”¨åŸºäºäº¤æ˜“å¯¹çš„åŠ¨æ€å€¼è€Œä¸æ˜¯å›ºå®šå€¼
                    import random
                    hash_value = hash(clean_sym_upper) % 100
                    sentiment_score = -0.3 + (hash_value / 100.0) * 0.6  # -0.3åˆ°0.3ä¹‹é—´çš„å€¼
                    sentiment_scores.append(sentiment_score)

                try:
                    anomaly_result = anomaly_detector.get_anomaly_summary(clean_sym_upper)
                    if anomaly_result:
                        has_anomaly = anomaly_result.get('has_anomaly', False)
                        if has_anomaly:
                            anomaly_count += 1
                except Exception as e:
                    logger.debug(f"å¼‚å¸¸æ£€æµ‹å¤±è´¥: {e}")

                save_analysis_results(clean_sym_upper, p, risk_level, market_regime, liquidity_score, sentiment_score, has_anomaly)

                tactic = get_tactical_decision(
                    trend, ratio, sar_diff, p, 0.02, 1.4,
                    risk_level, market_regime, liquidity_score, sentiment_score, has_anomaly
                )

                risk_color = "red" if risk_level == "HIGH" else ("yellow" if risk_level == "MEDIUM" else "green")
                regime_color = "green" if market_regime == "BULL" else ("red" if market_regime == "BEAR" else "cyan")
                liquidity_color = "green" if liquidity_score >= 0.7 else ("yellow" if liquidity_score >= 0.5 else "red")
                change_color = "green" if change_pct >= 0 else "red"
                sentiment_color = "green" if sentiment_score > 0.3 else ("red" if sentiment_score < -0.3 else "white")
                sentiment_emoji = "ğŸ˜Š" if sentiment_score > 0.3 else ("ğŸ˜°" if sentiment_score < -0.3 else "ğŸ˜")
                anomaly_emoji = "ğŸš¨" if has_anomaly else ""

                volume_str = f"{volume_24h/1e6:.1f}M" if volume_24h > 1e6 else f"{volume_24h/1e3:.1f}K"

                table.add_row(
                    sym,
                    f"{p:.2f}",
                    f"{change_pct:+.2f}%",
                    volume_str,
                    f"{sar_diff:+.2f}%",
                    pos_info,
                    pnl_str,
                    trend,
                    f"{ratio:+.4f}",
                    risk_level,
                    market_regime,
                    f"{liquidity_score:.2f}",
                    f"{sentiment_emoji}{sentiment_score:+.2f}",
                    tactic
                )

                if counter % 20 == 0: summary_batch.append(  # é™ä½AIåˆ†æé¢‘ç‡ï¼Œæ¯200ç§’ï¼ˆ20*10ç§’ï¼‰åˆ†æä¸€æ¬¡
                    f"{clean_sym_upper} Price:{p:.2f} Ratio:{ratio:.4f} Trend:{trend} SAR:{sar:.2f} Risk:{risk_level} Regime:{market_regime} Liquidity:{liquidity_score:.2f} Sentiment:{sentiment_score:.2f} Anomaly:{str(has_anomaly)}")

            avg_liquidity = sum(liquidity_scores) / len(liquidity_scores) if liquidity_scores else 1.0
            avg_sentiment = sum(sentiment_scores) / len(sentiment_scores) if sentiment_scores else 0.0
            
            liquidity_color = "green" if avg_liquidity >= 0.7 else ("yellow" if avg_liquidity >= 0.5 else "red")
            sentiment_color = "green" if avg_sentiment > 0.3 else ("red" if avg_sentiment < -0.3 else "white")
            
            # å¸‚åœºç»Ÿè®¡é¢æ¿
            stats_text = f"ğŸ“Š é£é™©: é«˜:{risk_summary['HIGH']} ä¸­:{risk_summary['MEDIUM']} ä½:{risk_summary['LOW']} | ğŸ‚ ç¯å¢ƒ: ç‰›:{regime_counts['BULL']} ç†Š:{regime_counts['BEAR']} éœ‡:{regime_counts['SIDEWAYS']} ?: {regime_counts['UNKNOWN']} | ğŸ’§æµåŠ¨: {avg_liquidity:.2f} | ğŸ˜Šæƒ…ç»ª: {avg_sentiment:+.2f} | ğŸš¨å¼‚å¸¸: {anomaly_count}"
            stats_panel = Panel(stats_text, title="ğŸ“ˆ å¸‚åœºç»Ÿè®¡", border_style="blue")
            
            # AIç­–ç•¥ç®€æŠ¥é¢æ¿
            with report_lock:
                ai_reports = "\n".join([f">> {r}" for r in ai_report_display[:10]])  # è¿›ä¸€æ­¥å¢åŠ AIæŠ¥å‘Šè¡Œæ•°ï¼Œåˆ©ç”¨æ›´å¤šç©ºé—´
            ai_panel = Panel(ai_reports if ai_reports else "æš‚æ— AIåˆ†æ", title="ğŸ§  ç­–ç•¥ç®€æŠ¥", border_style="green")
            
            # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡æ˜¯å¦éœ€è¦æ›´æ–°èµ„è®¯
            if counter % 6 == 0:  # æ¯åˆ†é’Ÿï¼ˆ10ç§’*6æ¬¡ï¼‰
                update_telegram_news()  # æ›´æ–°èµ„è®¯æ•°æ®
            
            # èµ„è®¯é¢æ¿
            news_list = get_latest_news(5)  # å¢åŠ æ˜¾ç¤ºæ•°é‡ï¼Œåˆ©ç”¨æ›´å¤šç©ºé—´
            if news_list:
                news_text = "\n".join([f"{i+1}. {source.split('_')[-1]} {timestamp[11:16]} {content[:100] + '...' if len(content) > 100 else content}" for i, (timestamp, source, content) in enumerate(news_list)])
            else:
                news_text = "æ— "
            news_panel = Panel(news_text, title="ğŸ“° æœ€æ–°èµ„è®¯", border_style="yellow")
            
            # çŠ¶æ€é¢æ¿
            status_text = f"ğŸ“¡ å®æ—¶æµ: ğŸŸ¢ | å¼•æ“: {'åˆ†æä¸­' if is_ai_calculating else 'å°±ç»ª'} | æ¨¡å¼: é‡åŒ– | è¿›åº¦: [{'â–ˆ' * (((counter // 6) % 10) + 1)}{'â–‘' * (9 - ((counter // 6) % 10))}]"  # é€‚åº”æ–°çš„åˆ·æ–°é¢‘ç‡ï¼Œæ¯åˆ†é’Ÿä¸€ä¸ªå®Œæ•´å‘¨æœŸ
            status_panel = Panel(status_text, title="çŠ¶æ€", border_style="cyan")
            
            # ç»„åˆä¸»å†…å®¹ - é‡æ–°è®¾è®¡å¸ƒå±€ï¼Œå°†AIç­–ç•¥ç®€æŠ¥ç§»åˆ°ä¸‹æ–¹
            main_layout = Layout()
            main_layout.split_column(
                Layout(table, name="table"),
                Layout(name="bottom_section", size=25)  # è¿›ä¸€æ­¥å¢åŠ åº•éƒ¨åŒºåŸŸé«˜åº¦ï¼Œä¸ºAIåˆ†æå’Œèµ„è®¯é¢„ç•™æ›´å¤šç©ºé—´
            )
            
            # åº•éƒ¨åŒºåŸŸåˆ†ä¸ºå·¦å³ä¸¤éƒ¨åˆ†
            bottom_layout = Layout(name="bottom")
            bottom_layout.split_row(
                Layout(ai_panel, name="ai", ratio=3),  # AIåˆ†æå ç”¨æ›´å¤šç©ºé—´
                Layout(name="right_pane", ratio=1)
            )
            
            # å³ä¾§åŒ…å«ç»Ÿè®¡ã€èµ„è®¯å’ŒçŠ¶æ€
            bottom_layout["right_pane"].split_column(
                Layout(stats_panel, name="stats"),
                Layout(news_panel, name="news"),
                Layout(status_panel, name="status")
            )
            
            main_layout["bottom_section"].update(bottom_layout)
            
            layout["main"].update(main_layout)
            
            if summary_batch and not is_ai_calculating:
                logger.debug(f"è§¦å‘ AI åˆ†æï¼ŒåŒ…å« {len(summary_batch)} ä¸ªèµ„äº§")
                threading.Thread(target=ai_inference_thread, args=("; ".join(summary_batch), bal)).start()
            
            counter += 1

            return layout
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆä»ªè¡¨ç›˜æ—¶å‡ºé”™: {e}")
            import traceback
            return Panel(f"âŒ ä»ªè¡¨ç›˜ç”Ÿæˆé”™è¯¯: {e}\n{traceback.format_exc()}", title="é”™è¯¯", border_style="red")
    
    # ä½¿ç”¨Richçš„LiveåŠŸèƒ½å®ç°å¹³æ»‘æ›´æ–°
    # é™ä½åˆ·æ–°é¢‘ç‡ä»¥å‡å°‘è§†è§‰ç–²åŠ³ï¼Œæ¯10ç§’åˆ·æ–°ä¸€æ¬¡
    with Live(generate_dashboard(), refresh_per_second=0.1, console=console) as live:  # 0.1 FPS = æ¯10ç§’åˆ·æ–°ä¸€æ¬¡
        while True:
            try:
                time.sleep(10)  # æ¯10ç§’æ›´æ–°ä¸€æ¬¡æ•°æ®
                live.update(generate_dashboard())
            except KeyboardInterrupt:
                break
            except Exception as e:
                logger.error(f"ä»ªè¡¨ç›˜æ›´æ–°å¼‚å¸¸: {e}")
                time.sleep(10)


if __name__ == "__main__":
    try:
        init_database()
        run_dashboard()
    except KeyboardInterrupt:
        logger.debug("æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨å…³é—­ç³»ç»Ÿ...")
        print("\n[ç³»ç»Ÿä¸‹çº¿] æ­£åœ¨é‡Šæ”¾èµ„æº...")
    except Exception as e:
        logger.error(f"ç³»ç»Ÿå´©æºƒ: {e}")
        raise